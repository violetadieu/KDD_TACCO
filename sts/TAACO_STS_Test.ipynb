{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import upload_file, delete_file,upload_folder\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from top2vec import Top2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44ba008",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = models.Transformer(\n",
    "    model_name_or_path=\"KDHyun08/TAACO_STS\", \n",
    "    max_seq_length=256,\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "pooling_model = models.Pooling(\n",
    "    embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")\n",
    "model = SentenceTransformer(modules=[embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426a7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "highschool=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7e1452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 놀이\n",
      "\n",
      "<입력 문장과 유사한 12 개의 문장>\n",
      "\n",
      "1: 놀이 (유사도: 1.0000)\n",
      "\n",
      "2: 대부분의 전래 놀이는 바깥에서 한다 (유사도: 0.4440)\n",
      "\n",
      "3: 대부분의 전래 놀이는 바깥에서 한다 (유사도: 0.4440)\n",
      "\n",
      "4: 우리 모두 전래 놀이에 관심을 가지고 즐겨 하자. (유사도: 0.3809)\n",
      "\n",
      "5: 이와 같이 전래 놀이를 하면 좋은 점이 많다 (유사도: 0.3220)\n",
      "\n",
      "6: 전래 놀이를 하면 다음과 같은 좋은 점이 있다.첫째, 자연을 가까이 느낄 수 있다 (유사도: 0.3001)\n",
      "\n",
      "7: 옛날 아이들은 윷놀이, 자치기, 팽이치기와 같은 전래 놀이를 하면서 친구들과 즐겁게 놀았다 (유사도: 0.2954)\n",
      "\n",
      "8: 요즘 아이들은 주로 인터넷 게임을 하거나 텔레비전을 시청하며 여가를 보낸다 (유사도: 0.2535)\n",
      "\n",
      "9: 또래 아이들과 함께 윷놀이나 비사치기를 하면서 의논하고 힘을 모으기도 한다 (유사도: 0.2410)\n",
      "\n",
      "10: 그래서 풀, 바람, 나무, 흙, 돌, 햇빛 등 자연을 가까이 느낄 수 있다 (유사도: 0.1256)\n",
      "\n",
      "11: 이러한 과정을 거치면서 아이들은 서로 돕고 위하는 태도를 배우게 된다 (유사도: 0.0991)\n",
      "\n",
      "12: 둘째, 공동체 의식을 기를 수 있다 (유사도: -0.0165)\n",
      "\n",
      "tensor(0.2627)\n"
     ]
    }
   ],
   "source": [
    "docs = ['어제는 아내의 생일이었다', '생일을 맞이하여 아침을 준비하겠다고 오전 8시 30분부터 음식을 준비하였다. 주된 메뉴는 스테이크와 낙지볶음, 미역국, 잡채, 소야 등이었다', '스테이크는 자주 하는 음식이어서 자신이 준비하려고 했다', '앞뒤도 1분씩 3번 뒤집고 래스팅을 잘 하면 육즙이 가득한 스테이크가 준비되다', '아내도 그런 스테이크를 좋아한다. 그런데 상상도 못한 일이 벌이지고 말았다', '보통 시즈닝이 되지 않은 원육을 사서 스테이크를 했는데, 이번에는 시즈닝이 된 부챗살을 구입해서 했다', '그런데 케이스 안에 방부제가 들어있는 것을 인지하지 못하고 방부제와 동시에 프라이팬에 올려놓을 것이다', '그것도 인지 못한 체... 앞면을 센 불에 1분을 굽고 뒤집는 순간 방부제가 함께 구어진 것을 알았다', '아내의 생일이라 맛있게 구워보고 싶었는데 어처구니없는 상황이 발생한 것이다', '방부제가 센 불에 녹아서 그런지 물처럼 흘러내렸다', ' 고민을 했다. 방부제가 묻은 부문만 제거하고 다시 구울까 했는데 방부제에 절대 먹지 말라는 문구가 있어서 아깝지만 버리는 방향을 했다', '너무나 안타까웠다', '아침 일찍 아내가 좋아하는 스테이크를 준비하고 그것을 맛있게 먹는 아내의 모습을 보고 싶었는데 전혀 생각지도 못한 상황이 발생해서... 하지만 정신을 추스르고 바로 다른 메뉴로 변경했다', '소야, 소시지 야채볶음..', '아내가 좋아하는지 모르겠지만 냉장고 안에 있는 후랑크소세지를 보니 바로 소야를 해야겠다는 생각이 들었다. 음식은 성공적으로 완성이 되었다', '40번째를 맞이하는 아내의 생일은 성공적으로 준비가 되었다', '맛있게 먹어 준 아내에게도 감사했다', '매년 아내의 생일에 맞이하면 아침마다 생일을 차려야겠다. 오늘도 즐거운 하루가 되었으면 좋겠다', '생일이니까~']\n",
    "text=\"놀이. 대부분의 전래 놀이는 바깥에서 한다. 옛날 아이들은 윷놀이, 자치기, 팽이치기와 같은 전래 놀이를 하면서 친구들과 즐겁게 놀았다. 요즘 아이들은 주로 인터넷 게임을 하거나 텔레비전을 시청하며 여가를 보낸다. 전래 놀이를 하면 다음과 같은 좋은 점이 있다.첫째, 자연을 가까이 느낄 수 있다. 대부분의 전래 놀이는 바깥에서 한다. 그래서 풀, 바람, 나무, 흙, 돌, 햇빛 등 자연을 가까이 느낄 수 있다. 둘째, 공동체 의식을 기를 수 있다. 또래 아이들과 함께 윷놀이나 비사치기를 하면서 의논하고 힘을 모으기도 한다. 이러한 과정을 거치면서 아이들은 서로 돕고 위하는 태도를 배우게 된다. 이와 같이 전래 놀이를 하면 좋은 점이 많다. 우리 모두 전래 놀이에 관심을 가지고 즐겨 하자.\"\n",
    "docs=re.split('\\. |\\? |\\!',text)\n",
    "\n",
    "#각 문장의 vector값 encoding\n",
    "document_embeddings = model.encode(docs)\n",
    "\n",
    "query = docs[0]\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "top_k = len(docs)\n",
    "score_sum=0.0\n",
    "# 코사인 유사도 계산 후,\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "# 코사인 유사도 순으로 문장 추출\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"\\n<입력 문장과 유사한 {top_k} 개의 문장>\\n\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    score_sum+=score\n",
    "    print(f\"{i+1}: {docs[idx]} {'(유사도: {:.4f})'.format(score)}\\n\")\n",
    "highschool+=(score_sum-1)/(top_k-1)\n",
    "print(highschool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "001a8c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 11:25:34,533 - top2vec - INFO - Pre-processing documents for training\n",
      "C:\\Users\\DESKTOP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "2023-01-12 11:27:01,507 - top2vec - INFO - Downloading distiluse-base-multilingual-cased model\n",
      "2023-01-12 11:27:02,941 - top2vec - INFO - Creating joint document/word embedding\n",
      "2023-01-12 15:28:45,029 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2023-01-12 15:31:22,572 - top2vec - INFO - Finding dense areas of documents\n",
      "2023-01-12 15:31:43,171 - top2vec - INFO - Finding topics\n"
     ]
    }
   ],
   "source": [
    "#Top2Vec 모델\n",
    "data=pd.read_csv(\"data/test.csv\")\n",
    "text=list()\n",
    "text=data['text'].to_list()\n",
    "model2=Top2Vec(documents=list(text),speed='fast-learn',workers=8,embedding_model='distiluse-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc76c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['영화산업이', '영화산업의', '영화산업에', '영화산업', '영화계의', '한국영화는', '한국영화를',\n",
       "        '한국영화의', '한국영화가', '영화제작에', '영화들은', '한국영화', '영화콘텐츠의', '영화에서',\n",
       "        '영화들을', '필름을', '영화들의', '영화제작', '한국영화에', '영화계', '일본영화', '영화들이',\n",
       "        '영화는', '필름의', '영화진흥위원회의', '극장에', '영화관', '영화진흥위원회', '영화를', '영화인',\n",
       "        'film', '극장에서', '극영화', '필름', '영화의', '자국영화', '독립영화', '극장을', '영화제',\n",
       "        '극장이', '극장용', '영화와', '할리우드의', '영화가', '극장', '한국산업인력공단', '극장은',\n",
       "        '영상물을', '영화', '예술영화']], dtype='<U15')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_nums = model2.get_topics(1)\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279cd251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5724424  0.52618325 0.52609956 0.5226298  0.5209547  0.51504314\n",
      "  0.51408887 0.51052535 0.49913186 0.44753253 0.43170786 0.35782516\n",
      "  0.3172083  0.31363225 0.30822423 0.30444226 0.29602402 0.28985986\n",
      "  0.28927082 0.27344716 0.26482677 0.2563244  0.25419402 0.25280416\n",
      "  0.25232914 0.25083512 0.2444829  0.23860112 0.23154777 0.23070747\n",
      "  0.22920698 0.2275315  0.21959925 0.21580896 0.21460935 0.21348289\n",
      "  0.21343178 0.212675   0.21184263 0.21048611 0.20994973 0.20991236\n",
      "  0.20986226 0.20672822 0.20572194 0.20547816 0.20131412 0.19975272\n",
      "  0.19876665 0.19852097]]\n"
     ]
    }
   ],
   "source": [
    "print(model2.get_documents_topics([0])[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=340391\n",
    "sum=0.0\n",
    "cnt=80\n",
    "for i in range(0,cnt):\n",
    "    try:\n",
    "        docutopi=model2.get_documents_topics([idx+i])[3][0][0]\n",
    "        sum+=docutopi\n",
    "    except:\n",
    "        break\n",
    "sum=sum/cnt\n",
    "print(sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1644eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc07d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
