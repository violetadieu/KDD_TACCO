{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fc6f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DESKTOP\\anaconda3\\envs\\a2\\lib\\site-packages\\huggingface_hub\\snapshot_download.py:11: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6728e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to C:\\Users\\DESKTOP/.huggingface/token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "#huggingface upload\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99541e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readKLUETrainData(path):\n",
    "    trainDataset=[]\n",
    "    with open(path,'rb')as file:\n",
    "        STSdata=json.load(file)\n",
    "    \n",
    "    for item in STSdata:\n",
    "        score=float(item['labels']['label'])/5.0\n",
    "\n",
    "        inputEx=InputExample(\n",
    "        texts=[item[\"sentence1\"],item[\"sentence2\"]],\n",
    "        label=score\n",
    "        )\n",
    "        trainDataset.append(inputEx)\n",
    "    \n",
    "    return trainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5917f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNLITrainData(path):\n",
    "    trainDataset=pd.DataFrame({\"sentence1\":[],\n",
    "                              \"sentence2\":[],\n",
    "                              \"score\":[]})\n",
    "    df = pd.read_csv(dataPath, on_bad_lines='skip')\n",
    "    \n",
    "    trainDataset[\"sentence1\"]=df[\"sentence1\"]\n",
    "    trainDataset[\"sentence2\"]=df[\"sentence2\"]\n",
    "    trainDataset[\"score\"]=df[\"score\"]\n",
    "    \n",
    "    return trainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d136bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCH=4\n",
    "outputPath=(modelName+\"_epoch-\"+str(EPOCH)).replace(\"/\",\"-\")\n",
    "outputPath='./outputs/'+outputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db4209c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DESKTOP\\anaconda3\\envs\\a2\\lib\\site-packages\\huggingface_hub\\file_download.py:563: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"KDHyun08/TAACO_STS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5e327d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538\n"
     ]
    }
   ],
   "source": [
    "dataPath=\"./dataset/train.csv\"\n",
    "\n",
    "trainDataset=readNLITrainData(dataPath)\n",
    "train_input=[]\n",
    "try:\n",
    "    for item in trainDataset.loc():\n",
    "        inputEx=InputExample(\n",
    "                texts=[item[\"sentence1\"],item[\"sentence2\"]],\n",
    "                label=float(item[\"score\"]/5.0)\n",
    "                )\n",
    "        train_input.append(inputEx)\n",
    "except:\n",
    "    print(len(train_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "007ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader=DataLoader(\n",
    "train_input,\n",
    "shuffle=True,\n",
    "batch_size=BATCH_SIZE\n",
    ")\n",
    "trainLoss=losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4d8f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "train_input,\n",
    "name=\"sts-vali\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "17f9ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DESKTOP\\anaconda3\\envs\\a2\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318d6eb5274c4eb3b09a0042b52f9cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7dc4749d5841db88c9bcbc395d5cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b97e2db50cd4a43a8801d9aca6dcd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 10.94 GiB already allocated; 0 bytes free; 11.30 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-57563a6bb3b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mevaluation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m  )\n",
      "\u001b[1;32m~\\Desktop\\github repo\\KDD_TACCO\\sts\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m    711\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\a2\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\a2\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 10.94 GiB already allocated; 0 bytes free; 11.30 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "train_objectives=[(trainDataLoader, trainLoss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=EPOCH,\n",
    "    evaluation_steps=1000,\n",
    "    output_path=outputPath\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./model\")\n",
    "model.save(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_folder(\n",
    "    folder_path =\"model\",\n",
    "    path_in_repo=\"\",\n",
    "    repo_id=\"KDHyun08/TAACO_STS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83775b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
